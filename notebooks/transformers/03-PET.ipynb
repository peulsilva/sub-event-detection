{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "while 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from src.utils import train_test_split, get_sample_weights, get_eval_set\n",
    "from src.preprocessing import preprocess_data\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel, DataCollatorForLanguageModeling, AutoModelForMaskedLM\n",
    "from src.preprocessing import TextDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, roc_auc_score\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, LoggingHandler\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from sklearn.decomposition import PCA\n",
    "from huggingface_hub import notebook_login\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from collections import defaultdict\n",
    "import transformers\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import re\n",
    "from bert_score import BERTScorer\n",
    "import langid\n",
    "from src.utils import aggregate_samples, evaluate_model, compute_class_weights, remove_hashtag_links, get_first_texts, validate_pet_model\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.97it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2022/pedro.silva/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 1472980/1472980 [01:33<00:00, 15762.42it/s]\n",
      "100%|██████████| 1472980/1472980 [00:01<00:00, 986963.01it/s] \n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(train_data)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data')\n",
    "df['tokens'] = df['Tweet'].progress_apply(tokenizer.tokenize)\n",
    "\n",
    "target_words = [\n",
    "    \"goal\", \"penalty\", \"halftime\", \"full-time\", \"yellow\", \"red\",\n",
    "    \"kickoff\", \"extra time\", \"stoppage time\", \"foul\", \"offside\", \"handball\",\n",
    "    \"save\", \"tackle\", \"dribble\", \"corner\", \"substitution\", \"header\",\n",
    "    \"free kick\", \"throw-in\", \"assist\", \"hat-trick\", \"own goal\", \"victory\",\n",
    "    \"defeat\", \"draw\", \"win\", \"loss\", \"tie\", \"comeback\", \"goalkeeper\",\n",
    "    \"striker\", \"midfielder\", \"defender\", \"referee\", \"fans\", \"var\", \"gooal\"\n",
    "]\n",
    "target_words = set(tokenizer.tokenize(\" \".join(target_words)))\n",
    "\n",
    "def is_valid_text(t):\n",
    "    for w in t:\n",
    "        if w in target_words:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "df['is_valid']= df['tokens'].progress_apply(is_valid_text)\n",
    "# df['lan'] = df['Tweet'].progress_apply(lambda x : langid.classify(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = df.query(\"is_valid == 1\")#.query(\"lan == 'en' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2022/pedro.silva/Desktop/sub-event-detection/src/utils.py:152: FutureWarning: The provided callable <function mean at 0x7f2298401f80> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return (df.query(f\"MatchID in {indices}\")).groupby([\"MatchID\", \"PeriodID\"]).agg({\n",
      "/users/eleves-a/2022/pedro.silva/Desktop/sub-event-detection/src/utils.py:152: FutureWarning: The provided callable <function mean at 0x7f2298401f80> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return (df.query(f\"MatchID in {indices}\")).groupby([\"MatchID\", \"PeriodID\"]).agg({\n"
     ]
    }
   ],
   "source": [
    "val_indices = [1,5,12,19]\n",
    "# val_indices = list(np.random.choice(all_train_indices, 3, replace=False))\n",
    "# train_indices = list(set(all_train_indices).difference(set(val_indices)))\n",
    "train_indices = [0,2,7,11,13,18]\n",
    "\n",
    "train_df = aggregate_samples(en_df, train_indices)\n",
    "val_df = aggregate_samples(en_df, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['prompt'] = train_df['Tweet'] + \"\\nIs there a tweet that indicates a football event like Goal, Halftime, Red or Yellow Card or Fulltime ? \"+ tokenizer.mask_token\n",
    "val_df['prompt'] = val_df['Tweet'] + \"\\nIs there a tweet that indicates a football event like Goal, Halftime, Red or Yellow Card or Fulltime ? \"+ tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label'] = train_df['EventType'].map({0:tokenizer.convert_tokens_to_ids(\"no\"), 1: tokenizer.convert_tokens_to_ids(\"yes\")})\n",
    "val_df['label'] = val_df['EventType'].map({0:tokenizer.convert_tokens_to_ids(\"no\"), 1: tokenizer.convert_tokens_to_ids(\"yes\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YesNoDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, mask_token=\"<mask>\", max_length=4096, device = 'cuda'):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.mask_token = mask_token\n",
    "        self.max_length = max_length\n",
    "        self.labels = labels\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Tokenize the text and ensure masking\n",
    "        text = self.texts[idx]\n",
    "        inputs = self.tokenizer(\n",
    "            text, \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            padding=\"longest\", \n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        input_ids = inputs.input_ids.squeeze()\n",
    "        \n",
    "        # Find and mask the token to predict\n",
    "        mask_index = torch.where(input_ids == self.tokenizer.mask_token_id)[0]\n",
    "        labels = input_ids.clone()\n",
    "        labels[:] = -100  # Set all to ignore_index (-100)\n",
    "        if mask_index.numel() > 0:\n",
    "            labels[mask_index] = self.labels[idx] # Keep the target at the masked position\n",
    "        return {\n",
    "            \"input_ids\": input_ids.to(self.device),\n",
    "            \"attention_mask\": inputs.attention_mask.squeeze().to(self.device),\n",
    "            \"labels\": labels.to(self.device)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = YesNoDataset(\n",
    "    train_df['prompt'].tolist(),\n",
    "    train_df['label'].tolist(),\n",
    "    tokenizer,\n",
    "    tokenizer.mask_token\n",
    ")\n",
    "\n",
    "val_dataset = YesNoDataset(\n",
    "    val_df['prompt'].tolist(),\n",
    "    val_df['label'].tolist(),\n",
    "    tokenizer,\n",
    "    tokenizer.mask_token\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [01:25<00:00,  9.15it/s]\n",
      "Validation: 100%|██████████| 487/487 [00:13<00:00, 37.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5585\n",
      "[[  0 215]\n",
      " [  0 272]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [01:25<00:00,  9.16it/s]\n",
      "Validation: 100%|██████████| 487/487 [00:12<00:00, 37.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5585\n",
      "[[  0 215]\n",
      " [  0 272]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 780/780 [01:25<00:00,  9.16it/s]\n",
      "Validation: 100%|██████████| 487/487 [00:12<00:00, 37.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5585\n",
      "[[  0 215]\n",
      " [  0 272]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the data\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data')\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    # collate_fn=DataCollatorForLanguageModeling(\n",
    "    #     tokenizer=tokenizer,\n",
    "    #     mlm=True,\n",
    "    #     mlm_probability=0.15\n",
    "    # )\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    # collate_fn=DataCollatorForLanguageModeling(\n",
    "    #     tokenizer=tokenizer,\n",
    "    #     mlm=True,\n",
    "    #     mlm_probability=0.15\n",
    "    # )\n",
    ")\n",
    "allowed_tokens = tokenizer.convert_tokens_to_ids([\"no\", \"yes\"])\n",
    "# Load the model\n",
    "# model = AutoModelForMaskedLM.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data')\n",
    "# model = model.to(\"cuda\")\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "        attention_mask = batch[\"attention_mask\"].to(\"cuda\")\n",
    "        labels = batch[\"labels\"].to(\"cuda\")\n",
    "\n",
    "        with torch.autocast( device_type = 'cuda'):\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits  # Shape: (batch_size, seq_len, vocab_size)\n",
    "\n",
    "        # Create a mask to identify `[MASK]` positions\n",
    "            mask_positions = (input_ids == tokenizer.mask_token_id)  # Shape: (batch_size, seq_len)\n",
    "\n",
    "            # Extract logits for `[MASK]` positions only\n",
    "            masked_logits = logits[mask_positions]  # Shape: (num_masks, vocab_size)\n",
    "\n",
    "            # Filter logits to include only \"yes\" and \"no\"\n",
    "            allowed_logits = masked_logits[:, allowed_tokens]  # Shape: (num_masks, len(allowed_tokens))\n",
    "\n",
    "            # Create the corresponding target labels (mapped to indices in allowed_tokens)\n",
    "            target_labels = labels[mask_positions]  # Shape: (num_masks)\n",
    "            remapped_labels = torch.zeros_like(target_labels)\n",
    "            for i, token_id in enumerate(allowed_tokens):\n",
    "                remapped_labels[target_labels == token_id] = i\n",
    "\n",
    "            # Compute loss only for `[MASK]` tokens\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()  # No ignore_index needed as we filter positions\n",
    "            loss = loss_fn(allowed_logits, remapped_labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    y_pred_val , y_true_val = validate_pet_model(model, val_dataloader, tokenizer, allowed_tokens)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remapped_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_probs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
