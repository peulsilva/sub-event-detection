{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "while 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from src.utils import train_test_split, get_sample_weights, get_eval_set\n",
    "from src.preprocessing import preprocess_data\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from src.preprocessing import TextDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, roc_auc_score\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, LoggingHandler\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from sklearn.decomposition import PCA\n",
    "from huggingface_hub import notebook_login\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from collections import defaultdict\n",
    "import transformers\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import re\n",
    "from bert_score import BERTScorer\n",
    "import langid\n",
    "from src.utils import aggregate_samples, evaluate_model, compute_class_weights, remove_hashtag_links\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:06<00:00,  2.66it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_text = \"Threre was a goal, half time, kick-off, full time, penalty, red card, yellow card, or own goal\"\n",
    "# # Define batch size\n",
    "# batch_size = 1024\n",
    "\n",
    "# # Initialize lists to store scores\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# f1_scores = []\n",
    "\n",
    "# data = pd.concat(train_data.values())\n",
    "\n",
    "# # Create a progress bar\n",
    "# for i in tqdm(range(0, len(data), batch_size), desc=\"Scoring Batches\"):\n",
    "#     # Slice the batch\n",
    "#     batch = data.iloc[i:i + batch_size]['Tweet'].tolist()\n",
    "    \n",
    "#     # Compute BERTScore for the batch\n",
    "#     P, R, F1 = scorer.score(batch, [sample_text] * len(batch), )\n",
    "    \n",
    "#     # Append scores\n",
    "#     precisions.extend(P.tolist())\n",
    "#     recalls.extend(R.tolist())\n",
    "#     f1_scores.extend(F1.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = pd.concat(train_data.values())\n",
    "# all_df['bertscore'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = all_df.groupby([\"MatchID\", \"PeriodID\"], as_index=False).apply(lambda x: x.sort_values(\"bertscore\").iloc[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2022/pedro.silva/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 1472980/1472980 [01:43<00:00, 14241.45it/s]\n",
      "100%|██████████| 1472980/1472980 [00:01<00:00, 982258.79it/s] \n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(train_data)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", cache_dir = '/Data')\n",
    "df['tokens'] = df['Tweet'].progress_apply(tokenizer.tokenize)\n",
    "\n",
    "target_words = \"goal goooal score yellow card red overtime time halftime half start end kickoff kick penalty \"\n",
    "target_words = set(tokenizer.tokenize(target_words))\n",
    "\n",
    "def is_valid_text(t):\n",
    "    for w in t:\n",
    "        if w in target_words:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "df['is_valid']= df['tokens'].progress_apply(is_valid_text)\n",
    "# df['lan'] = df['Tweet'].progress_apply(lambda x : langid.classify(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = df#.query(\"lan == 'en' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_indices = set(train_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488553/2907081575.py:21: FutureWarning: The provided callable <function mean at 0x7f07701ddf80> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return (df.query(f\"MatchID in {indices}\")).groupby([\"MatchID\", \"PeriodID\"]).agg({\n",
      "/tmp/ipykernel_1488553/2907081575.py:14: FutureWarning: The provided callable <function mean at 0x7f07701ddf80> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return pd.concat(all_df).groupby([\"MatchID\", \"PeriodID\"]).agg({\n",
      "/tmp/ipykernel_1488553/2907081575.py:21: FutureWarning: The provided callable <function mean at 0x7f07701ddf80> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return (df.query(f\"MatchID in {indices}\")).groupby([\"MatchID\", \"PeriodID\"]).agg({\n"
     ]
    }
   ],
   "source": [
    "test_indices = list(np.random.choice(list(possible_indices), size=3, replace = False,))\n",
    "test_indices = [13,1,18]\n",
    "all_train_indices = list(possible_indices.difference(set(test_indices)))\n",
    "val_indices = [1,5,12,19]\n",
    "# val_indices = list(np.random.choice(all_train_indices, 3, replace=False))\n",
    "# train_indices = list(set(all_train_indices).difference(set(val_indices)))\n",
    "train_indices = [0,2,7,11,13,18]\n",
    "\n",
    "\n",
    "train_df = aggregate_samples(train_indices,df = en_df)\n",
    "# train_df = get_samples(train_indices, df = train)\n",
    "test_df = aggregate_samples(test_indices)\n",
    "val_df = aggregate_samples(val_indices, df = en_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = remove_hashtag_links(train_df)\n",
    "test_df = remove_hashtag_links(test_df)\n",
    "val_df = remove_hashtag_links(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 14, 1]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.6931818181818182\n",
      "\n",
      "Validation auc : 0.6933850129198966\n",
      "\n",
      "[[154  71]\n",
      " [ 64 151]]\n"
     ]
    }
   ],
   "source": [
    "# K Fold CV\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", cache_dir = '/Data')\n",
    "\n",
    "device = 'cuda'\n",
    "final_results = []\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    train_df[\"Tweet\"].tolist(), \n",
    "    train_df['ID'].tolist(),\n",
    "    train_df[\"EventType\"].tolist(), \n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = TextDataset(\n",
    "    val_df[\"Tweet\"].tolist(), \n",
    "    val_df['ID'].tolist(),\n",
    "    val_df[\"EventType\"].tolist(), \n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = TextDataset(\n",
    "    test_df[\"Tweet\"].tolist(), \n",
    "    test_df['ID'].tolist(),\n",
    "    test_df[\"EventType\"].tolist(), \n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", cache_dir = '/Data', num_labels = 2, dropout = 0.4)\n",
    "# model.resize_position_embeddings(2048)\n",
    "\n",
    "# model = BertWithExtraFeature(bert_model_name=\"bert-base-uncased\")\n",
    "\n",
    "# for p in model.distlbert.parameters():\n",
    "#     p.requires_grad = False\n",
    "model.to(device)\n",
    "\n",
    "# model = get_peft_model(base_model, lora_config)\n",
    "# for param in model.bert.parameters():\n",
    "#     param.requires_grad = False\n",
    "    \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4,)\n",
    "\n",
    "# optimizer = torch.optim.AdamW([\n",
    "#     {'params': model.bert.parameters(), 'weight_decay': 1e-3},  # Regularize BERT weights\n",
    "#     {'params': model.fc.parameters(), 'weight_decay': 1e-2}     # Stronger regularization on the classifier\n",
    "# ], lr=1e-5)\n",
    "\n",
    "for name, param in model.distilbert.named_parameters():\n",
    "    if \"layer.5\" in name or \"layer.4\" in name:  # Unfreeze last two layers\n",
    "        param.requires_grad = True\n",
    "\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "best_model = None\n",
    "second_best_model = None\n",
    "best_acc = -1\n",
    "second_best_acc = -1\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "labels = train_df[\"EventType\"].tolist()\n",
    "class_weight = torch.Tensor([0.4, 0.6]).to(device)\n",
    "# class_weights = compute_class_weights(labels).to(device)\n",
    "\n",
    "# Define weighted loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss(class_weight)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    epoch_loss = 0\n",
    "\n",
    "    print(train_indices, val_indices)\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        count = batch['count'].to(device).unsqueeze(dim = -1)\n",
    "\n",
    "        with torch.autocast( device_type = 'cuda'):\n",
    "            # outputs = model(input_ids=input_ids, attention_mask=attention_mask, extra_feature = count)\n",
    "            # loss = loss_fn(outputs, labels.squeeze() )\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels = labels)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            # loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        # preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    acc_train = accuracy_score(all_labels, all_preds, )\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"---------- Epoch {epoch} ------------\")\n",
    "    print(f\"Training Loss : {epoch_loss}\\n\")\n",
    "    print(f\"Training Accuracy : {acc_train}\\n\")\n",
    "    print(f\"Training Precision : {precision}\\n\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "\n",
    "    preds, labels = evaluate_model(val_df, val_dataloader, model, extra_feature=False)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    # if acc_train > 0.8 and acc > 0.68:\n",
    "    #     best_model = deepcopy(model)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        second_best_acc = best_acc\n",
    "        second_best_model = deepcopy(best_model)  # Promote previous best to second best\n",
    "        best_acc = acc\n",
    "        best_model = deepcopy(model)\n",
    "    # elif acc > second_best_acc:\n",
    "    #     second_best_acc = acc\n",
    "    #     second_best_model = deepcopy(model)\n",
    "\n",
    "\n",
    "# Combine results for this fold\n",
    "# validation_results = pd.DataFrame({\n",
    "#     \"MatchID\": validation_data[\"MatchID\"].values,\n",
    "#     \"true_values\": labels,\n",
    "#     \"predictions\": preds,\n",
    "# })\n",
    "\n",
    "# final_results.append(validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# class TweetDataset(Dataset):\n",
    "#     def __init__(self, tweets, tokenizer, max_length=512):\n",
    "#         self.tweets = tweets\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.tweets)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.tokenizer(\n",
    "#             self.tweets[idx],\n",
    "#             return_tensors='pt',\n",
    "#             truncation=True,\n",
    "#             padding='max_length',\n",
    "#             max_length=self.max_length\n",
    "#         )\n",
    "\n",
    "# # Define a dataset\n",
    "\n",
    "# def get_X(texts):\n",
    "#     tweet_dataset = TweetDataset(\n",
    "#         tweets=texts,\n",
    "#         tokenizer=tokenizer,\n",
    "#         max_length=512\n",
    "#     )\n",
    "\n",
    "#     # Create a DataLoader for batching\n",
    "#     batch_size = 32  # Adjust batch size based on available GPU memory\n",
    "#     data_loader = DataLoader(tweet_dataset, batch_size=batch_size)\n",
    "\n",
    "#     X_train_list = []  # To store processed embeddings\n",
    "\n",
    "#     # Process in batches\n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(data_loader):\n",
    "#             # Move tokenized input to GPU\n",
    "#             b = {k: v.squeeze().to(\"cuda\") for k, v in batch.items()}  # Squeeze to match model input shape\n",
    "            \n",
    "#             # Model forward pass\n",
    "#             outputs = best_model.distilbert(**b)\n",
    "            \n",
    "#             # Collect the embeddings (modify based on your use case, e.g., logits, hidden states, etc.)\n",
    "#             X_train_list.append(outputs.last_hidden_state[:,-1,:].to(\"cpu\"))\n",
    "\n",
    "#     # Concatenate all batches if needed\n",
    "#     X = torch.cat(X_train_list, dim=0)\n",
    "    \n",
    "#     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.6846153846153846\n",
      "\n",
      "Validation auc : 0.6778722030981066\n",
      "\n",
      "[[105  61]\n",
      " [ 62 162]]\n"
     ]
    }
   ],
   "source": [
    "preds, labels = evaluate_model(test_df, test_dataloader, best_model, extra_feature=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1488553/2907081575.py:21: FutureWarning: The provided callable <function mean at 0x7f07701ddf80> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return (df.query(f\"MatchID in {indices}\")).groupby([\"MatchID\", \"PeriodID\"]).agg({\n",
      "/tmp/ipykernel_1488553/2907081575.py:21: FutureWarning: The provided callable <function mean at 0x7f07701ddf80> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return (df.query(f\"MatchID in {indices}\")).groupby([\"MatchID\", \"PeriodID\"]).agg({\n"
     ]
    }
   ],
   "source": [
    "# val_indices = list(np.random.choice(list(train_data.keys()), size=6, replace = False))\n",
    "# train_indices = list(set(train_data.keys()).difference(set(val_indices)))\n",
    "\n",
    "val_indices = [1,5,12,19]\n",
    "# val_indices = list(np.random.choice(all_train_indices, 3, replace=False))\n",
    "# train_indices = list(set(all_train_indices).difference(set(val_indices)))\n",
    "train_indices = [0,2,7,11,13,18]\n",
    "\n",
    "\n",
    "\n",
    "# train_df = get_samples(train_indices, df = train)\n",
    "train_df = aggregate_samples(train_indices, df = en_df)\n",
    "val_df = aggregate_samples(val_indices, df = en_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = remove_hashtag_links(train_df, )\n",
    "val_df = remove_hashtag_links(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "1.0    0.567949\n",
       "0.0    0.432051\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['EventType'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "1.0    0.558522\n",
       "0.0    0.441478\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['EventType'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2022/pedro.silva/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 7, 11, 13, 18] [1, 5, 12, 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# K Fold CV\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data')\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "final_results = []\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    train_df[\"Tweet\"].tolist(), \n",
    "    train_df['ID'].tolist(),\n",
    "    train_df[\"EventType\"].tolist(), \n",
    "    tokenizer,\n",
    "    train_df.index.get_level_values(\"MatchID\").tolist()\n",
    "\n",
    ")\n",
    "\n",
    "val_dataset = TextDataset(\n",
    "    val_df[\"Tweet\"].tolist(), \n",
    "    val_df['ID'].tolist(),\n",
    "    val_df[\"EventType\"].tolist(), \n",
    "    tokenizer,\n",
    "    val_df.index.get_level_values(\"MatchID\").tolist()\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data', num_labels = 2,ignore_mismatched_sizes=True)\n",
    "# for p in base_model.model.parameters():\n",
    "#     p.requires_grad = False\n",
    "model.to(device)\n",
    "\n",
    "# model = get_peft_model(base_model, lora_config)\n",
    "# for param in model.bert.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "for name, param in model.longformer.named_parameters():\n",
    "    if \"layer.11\" in name:  # Unfreeze last two layers\n",
    "        param.requires_grad = True\n",
    "\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "labels = train_df[\"EventType\"].tolist()\n",
    "class_weights = torch.Tensor([0.4,0.6]).to(device)\n",
    "\n",
    "# Define weighted loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss(class_weights)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    epoch_loss = 0\n",
    "\n",
    "    print(train_indices, val_indices)\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        with torch.autocast( device_type = 'cuda'):\n",
    "            # outputs = model(input_ids=input_ids, attention_mask=attention_mask, extra_feature = count)\n",
    "            # loss = loss_fn(outputs, labels.squeeze() )\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels = labels)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds, )\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"---------- Epoch {epoch} ------------\")\n",
    "    print(f\"Training Loss : {epoch_loss}\\n\")\n",
    "    print(f\"Training Accuracy : {acc}\\n\")\n",
    "    print(f\"Training Precision : {precision}\\n\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "\n",
    "    preds, labels = evaluate_model(val_df, val_dataloader, model)\n",
    "\n",
    "    acc = roc_auc_score(labels, preds)\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = deepcopy(model)\n",
    "\n",
    "\n",
    "# Combine results for this fold\n",
    "# validation_results = pd.DataFrame({\n",
    "#     \"MatchID\": validation_data[\"MatchID\"].values,\n",
    "#     \"true_values\": labels,\n",
    "#     \"predictions\": preds,\n",
    "# })\n",
    "\n",
    "# final_results.append(validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "total_test_df = get_eval_set().set_index([\"MatchID\", \"PeriodID\"])\n",
    "test_df = preprocess_data(total_test_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_text = \"Threre was a goal, half time, kick-off, full time, penalty, red card, yellow card, or own goal\"\n",
    "# # Define batch size\n",
    "# batch_size = 1024\n",
    "\n",
    "# # Initialize lists to store scores\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# # f1_scores = []\n",
    "\n",
    "# data = test_df\n",
    "\n",
    "# # Create a progress bar\n",
    "# for i in tqdm(range(0, len(data), batch_size), desc=\"Scoring Batches\"):\n",
    "#     # Slice the batch\n",
    "#     batch = data.iloc[i:i + batch_size]['Tweet'].tolist()\n",
    "    \n",
    "#     # Compute BERTScore for the batch\n",
    "#     P, R, F1 = scorer.score(batch, [sample_text] * len(batch), )\n",
    "    \n",
    "#     # Append scores\n",
    "#     precisions.extend(P.tolist())\n",
    "#     recalls.extend(R.tolist())\n",
    "    # f1_scores.extend(F1.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['bertscore'] = f1_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = test_df.groupby([\"MatchID\", \"PeriodID\"], as_index=False).apply(lambda x: x.sort_values(\"bertscore\").iloc[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 362397/362397 [04:03<00:00, 1490.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# test_df['lan'] = test_df['Tweet'].progress_apply(langid.classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['language'] = test_df['lan'].apply(lambda x: x[0])\n",
    "test_df['language'] = \"en\"\n",
    "\n",
    "test_df_en = test_df.query(\"language == 'en' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_df = test_df_en.groupby([\"MatchID\", \"PeriodID\"]).agg({\n",
    "    \"Tweet\":    get_first_texts,\n",
    "    \"ID\": len\n",
    "})\n",
    "\n",
    "processed_test_df = remove_hashtag_links(processed_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th>0</th>\n",
       "      <td>I Finally get to see Germany play\\n   \\nFascin...</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"In a few minutes  of  x ...Can't wait\"....Waa...</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I don't see any team in this World Cup that ca...</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Future World Cup champions are about to play.....</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thing is.. Ozil looks like one of my aquarium ...</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">16</th>\n",
       "      <th>125</th>\n",
       "      <td>Someone here just described Group D as \"litera...</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Stat comparison between Serbia &amp; Germany s int...</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>OMFG  just lost??? I'm glad I'm at work then! ...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>ç›´å‰äºˆæƒ³0-0ã¯å¤–ã‚Œã€‚ã‚»ãƒ«ãƒ“ã‚¢å„ªä½ã...</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>:)))) Nije mala, nije mala...   !!!!!!\\nFive h...</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Tweet   ID\n",
       "MatchID PeriodID                                                        \n",
       "6       0         I Finally get to see Germany play\\n   \\nFascin...  237\n",
       "        1         \"In a few minutes  of  x ...Can't wait\"....Waa...  245\n",
       "        2         I don't see any team in this World Cup that ca...  254\n",
       "        3         Future World Cup champions are about to play.....  344\n",
       "        4         Thing is.. Ozil looks like one of my aquarium ...  456\n",
       "...                                                             ...  ...\n",
       "16      125       Someone here just described Group D as \"litera...  344\n",
       "        126       Stat comparison between Serbia & Germany s int...  315\n",
       "        127       OMFG  just lost??? I'm glad I'm at work then! ...  300\n",
       "        128       ç›´å‰äºˆæƒ³0-0ã¯å¤–ã‚Œã€‚ã‚»ãƒ«ãƒ“ã‚¢å„ªä½ã...  273\n",
       "        129       :)))) Nije mala, nije mala...   !!!!!!\\nFive h...  241\n",
       "\n",
       "[516 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TextDataset(\n",
    "    processed_test_df[\"Tweet\"].tolist(), \n",
    "    processed_test_df['ID'].tolist(), \n",
    "    None,\n",
    "    tokenizer,\n",
    "    [0] * 516\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 11/17 [00:28<00:17,  2.85s/it]"
     ]
    }
   ],
   "source": [
    "preds, labels, probas = evaluate_model(processed_test_df, test_dataloader, best_model, use_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_df['EventType'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "0    0.614341\n",
       "1    0.385659\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_df['EventType'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['EventType'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m      2\u001b[0m     total_test_df,\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTweet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEventType\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      4\u001b[0m     left_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m )[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEventType\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]]\\\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mdrop_duplicates(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions_2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/pay_attention_to_what_matters/.conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['EventType'] not in index\""
     ]
    }
   ],
   "source": [
    "pd.merge(\n",
    "    total_test_df,\n",
    "    test_df[[\"Tweet\", \"EventType\"]],\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "\n",
    ")[['EventType','ID']]\\\n",
    "    .drop_duplicates(\"ID\")\\\n",
    "    .set_index(\"ID\")\\\n",
    "    .to_csv(\"predictions_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "0    0.831609\n",
       "1    0.168391\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
