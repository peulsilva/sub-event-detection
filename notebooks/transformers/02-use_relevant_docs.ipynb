{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "while 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from src.utils import train_test_split, get_sample_weights, get_eval_set\n",
    "from src.preprocessing import preprocess_data\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from src.preprocessing import TextDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, roc_auc_score\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, LoggingHandler\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from sklearn.decomposition import PCA\n",
    "from huggingface_hub import notebook_login\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from collections import defaultdict\n",
    "import transformers\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import re\n",
    "from bert_score import BERTScorer\n",
    "import langid\n",
    "from src.utils import aggregate_samples, evaluate_model, compute_class_weights, remove_hashtag_links, get_first_texts\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:05<00:00,  2.71it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_text = \"Threre was a goal, half time, kick-off, full time, penalty, red card, yellow card, or own goal\"\n",
    "# # Define batch size\n",
    "# batch_size = 1024\n",
    "\n",
    "# # Initialize lists to store scores\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# f1_scores = []\n",
    "\n",
    "# data = pd.concat(train_data.values())\n",
    "\n",
    "# # Create a progress bar\n",
    "# for i in tqdm(range(0, len(data), batch_size), desc=\"Scoring Batches\"):\n",
    "#     # Slice the batch\n",
    "#     batch = data.iloc[i:i + batch_size]['Tweet'].tolist()\n",
    "    \n",
    "#     # Compute BERTScore for the batch\n",
    "#     P, R, F1 = scorer.score(batch, [sample_text] * len(batch), )\n",
    "    \n",
    "#     # Append scores\n",
    "#     precisions.extend(P.tolist())\n",
    "#     recalls.extend(R.tolist())\n",
    "#     f1_scores.extend(F1.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_df = pd.concat(train_data.values())\n",
    "# all_df['bertscore'] = f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = all_df.groupby([\"MatchID\", \"PeriodID\"], as_index=False).apply(lambda x: x.sort_values(\"bertscore\").iloc[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1472980/1472980 [01:46<00:00, 13849.64it/s]\n",
      "100%|██████████| 1472980/1472980 [00:01<00:00, 853498.06it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(train_data)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data')\n",
    "df['tokens'] = df['Tweet'].progress_apply(tokenizer.tokenize)\n",
    "\n",
    "target_words = [\n",
    "    \"goal\", \"penalty\", \"halftime\", \"full-time\", \"yellow\", \"red\",\n",
    "    \"kickoff\", \"extra time\", \"stoppage time\", \"foul\", \"offside\", \"handball\",\n",
    "    \"save\", \"tackle\", \"dribble\", \"corner\", \"substitution\", \"header\",\n",
    "    \"free kick\", \"throw-in\", \"assist\", \"hat-trick\", \"own goal\", \"victory\",\n",
    "    \"defeat\", \"draw\", \"win\", \"loss\", \"tie\", \"comeback\", \"goalkeeper\",\n",
    "    \"striker\", \"midfielder\", \"defender\", \"referee\", \"fans\", \"var\", \"gooal\"\n",
    "]\n",
    "target_words = set(tokenizer.tokenize(\" \".join(target_words)))\n",
    "\n",
    "def is_valid_text(t):\n",
    "    for w in t:\n",
    "        if w in target_words:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "df['is_valid']= df['tokens'].progress_apply(is_valid_text)\n",
    "# df['lan'] = df['Tweet'].progress_apply(lambda x : langid.classify(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = df.query(\"is_valid == 1\")#.query(\"lan == 'en' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>14</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725802000</td>\n",
       "      <td>Let's go Honduras, with a little help from Fra...</td>\n",
       "      <td>[Let, 's, Ġgo, ĠHonduras, ,, Ġwith, Ġa, Ġlittl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725806000</td>\n",
       "      <td>The more goals France scores today the less go...</td>\n",
       "      <td>[The, Ġmore, Ġgoals, ĠFrance, Ġscores, Ġtoday,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725807000</td>\n",
       "      <td>Robbie Fowler predicting a Honduras win? #Worl...</td>\n",
       "      <td>[Rob, bie, ĠFowler, Ġpredicting, Ġa, ĠHonduras...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725809000</td>\n",
       "      <td>#WorldCup2014 lets go Ecuador lets go Honduras</td>\n",
       "      <td>[#, World, C, up, 2014, Ġlets, Ġgo, ĠEcuador, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725818000</td>\n",
       "      <td>I’m following Honduras versus Switzerland in t...</td>\n",
       "      <td>[I, âĢ, Ļ, m, Ġfollowing, ĠHonduras, Ġversus, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">19</th>\n",
       "      <th>155326</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560797000</td>\n",
       "      <td>#mirelagh: #WorldCup2014/ #WM2014 / Full Time:...</td>\n",
       "      <td>[#, mire, l, agh, :, Ġ#, World, C, up, 2014, /...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155330</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560798000</td>\n",
       "      <td>Great win can't wait for next game #MEX</td>\n",
       "      <td>[Great, Ġwin, Ġcan, 't, Ġwait, Ġfor, Ġnext, Ġg...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155448</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560799000</td>\n",
       "      <td>Round of 16 - 29 de Junio #MEX vs #NED #Brasil...</td>\n",
       "      <td>[Round, Ġof, Ġ16, Ġ-, Ġ29, Ġde, ĠJun, io, Ġ#, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155458</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560799000</td>\n",
       "      <td>Holland better not let up, El Tri is coming fo...</td>\n",
       "      <td>[H, oll, and, Ġbetter, Ġnot, Ġlet, Ġup, ,, ĠEl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155507</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560800000</td>\n",
       "      <td>We took over Twitter today lmao #MEX</td>\n",
       "      <td>[We, Ġtook, Ġover, ĠTwitter, Ġtoday, Ġl, ma, o...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476071 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  MatchID  PeriodID  EventType      Timestamp  \\\n",
       "0  14         0_0        0         0          0  1403725802000   \n",
       "   29         0_0        0         0          0  1403725806000   \n",
       "   36         0_0        0         0          0  1403725807000   \n",
       "   41         0_0        0         0          0  1403725809000   \n",
       "   76         0_0        0         0          0  1403725818000   \n",
       "...           ...      ...       ...        ...            ...   \n",
       "19 155326  19_129       19       129          1  1403560797000   \n",
       "   155330  19_129       19       129          1  1403560798000   \n",
       "   155448  19_129       19       129          1  1403560799000   \n",
       "   155458  19_129       19       129          1  1403560799000   \n",
       "   155507  19_129       19       129          1  1403560800000   \n",
       "\n",
       "                                                       Tweet  \\\n",
       "0  14      Let's go Honduras, with a little help from Fra...   \n",
       "   29      The more goals France scores today the less go...   \n",
       "   36      Robbie Fowler predicting a Honduras win? #Worl...   \n",
       "   41         #WorldCup2014 lets go Ecuador lets go Honduras   \n",
       "   76      I’m following Honduras versus Switzerland in t...   \n",
       "...                                                      ...   \n",
       "19 155326  #mirelagh: #WorldCup2014/ #WM2014 / Full Time:...   \n",
       "   155330            Great win can't wait for next game #MEX   \n",
       "   155448  Round of 16 - 29 de Junio #MEX vs #NED #Brasil...   \n",
       "   155458  Holland better not let up, El Tri is coming fo...   \n",
       "   155507               We took over Twitter today lmao #MEX   \n",
       "\n",
       "                                                      tokens  is_valid  \n",
       "0  14      [Let, 's, Ġgo, ĠHonduras, ,, Ġwith, Ġa, Ġlittl...      True  \n",
       "   29      [The, Ġmore, Ġgoals, ĠFrance, Ġscores, Ġtoday,...      True  \n",
       "   36      [Rob, bie, ĠFowler, Ġpredicting, Ġa, ĠHonduras...      True  \n",
       "   41      [#, World, C, up, 2014, Ġlets, Ġgo, ĠEcuador, ...      True  \n",
       "   76      [I, âĢ, Ļ, m, Ġfollowing, ĠHonduras, Ġversus, ...      True  \n",
       "...                                                      ...       ...  \n",
       "19 155326  [#, mire, l, agh, :, Ġ#, World, C, up, 2014, /...      True  \n",
       "   155330  [Great, Ġwin, Ġcan, 't, Ġwait, Ġfor, Ġnext, Ġg...      True  \n",
       "   155448  [Round, Ġof, Ġ16, Ġ-, Ġ29, Ġde, ĠJun, io, Ġ#, ...      True  \n",
       "   155458  [H, oll, and, Ġbetter, Ġnot, Ġlet, Ġup, ,, ĠEl...      True  \n",
       "   155507  [We, Ġtook, Ġover, ĠTwitter, Ġtoday, Ġl, ma, o...      True  \n",
       "\n",
       "[476071 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2022/pedro.silva/Desktop/sub-event-detection/src/utils.py:152: FutureWarning: The provided callable <function mean at 0x7f90881d5ee0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return (df.query(f\"MatchID in {indices}\")).groupby([\"MatchID\", \"PeriodID\"]).agg({\n",
      "/users/eleves-a/2022/pedro.silva/Desktop/sub-event-detection/src/utils.py:152: FutureWarning: The provided callable <function mean at 0x7f90881d5ee0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return (df.query(f\"MatchID in {indices}\")).groupby([\"MatchID\", \"PeriodID\"]).agg({\n",
      "/users/eleves-a/2022/pedro.silva/Desktop/sub-event-detection/src/utils.py:152: FutureWarning: The provided callable <function mean at 0x7f90881d5ee0> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  return (df.query(f\"MatchID in {indices}\")).groupby([\"MatchID\", \"PeriodID\"]).agg({\n"
     ]
    }
   ],
   "source": [
    "possible_indices = set(train_data.keys())\n",
    "\n",
    "test_indices = list(np.random.choice(list(possible_indices), size=3, replace = False,))\n",
    "test_indices = [13,1,18]\n",
    "all_train_indices = list(possible_indices.difference(set(test_indices)))\n",
    "val_indices = [1,5,4,12,19]\n",
    "# val_indices = list(np.random.choice(all_train_indices, 3, replace=False))\n",
    "# train_indices = list(set(all_train_indices).difference(set(val_indices)))\n",
    "train_indices = [0,3,2,7,11,]\n",
    "\n",
    "test_indices = [14,17,13, 18]\n",
    "\n",
    "\n",
    "train_df = aggregate_samples(en_df, train_indices, max_size = 10)\n",
    "# train_df = get_samples(train_indices, df = train)\n",
    "test_df = aggregate_samples(en_df, test_indices, max_size=10)\n",
    "val_df = aggregate_samples(en_df, val_indices, max_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = remove_hashtag_links(train_df)\n",
    "test_df = remove_hashtag_links(test_df)\n",
    "val_df = remove_hashtag_links(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 17, 13, 18]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "1.0    0.550769\n",
       "0.0    0.449231\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['EventType'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "1.0    0.528158\n",
       "0.0    0.471842\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['EventType'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "1.0    0.551923\n",
       "0.0    0.448077\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['EventType'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Fold CV\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data')\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "final_results = []\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    train_df[\"Tweet\"].tolist(), \n",
    "    train_df['ID'].tolist(),\n",
    "    train_df[\"EventType\"].tolist(), \n",
    "    tokenizer,\n",
    "    train_df.index.get_level_values(\"MatchID\").tolist()\n",
    "\n",
    ")\n",
    "\n",
    "val_dataset = TextDataset(\n",
    "    val_df[\"Tweet\"].tolist(), \n",
    "    val_df['ID'].tolist(),\n",
    "    val_df[\"EventType\"].tolist(), \n",
    "    tokenizer,\n",
    "    val_df.index.get_level_values(\"MatchID\").tolist()\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=data_collator)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data', num_labels = 2,ignore_mismatched_sizes=True)\n",
    "# for p in base_model.model.parameters():\n",
    "#     p.requires_grad = False\n",
    "model.to(device)\n",
    "\n",
    "# model = get_peft_model(base_model, lora_config)\n",
    "# for param in model.bert.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "for name, param in model.longformer.named_parameters():\n",
    "    if \"layer.11\" in name or \"layer.10\":  # Unfreeze last two layers\n",
    "        param.requires_grad = True\n",
    "\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "labels = train_df[\"EventType\"].tolist()\n",
    "\n",
    "class_weights = compute_class_weights(train_df['EventType']).to(device)\n",
    "# class_weights = torch.Tensor([0.6,0.4]).to(device)\n",
    "\n",
    "# Define weighted loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss(class_weights)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    epoch_loss = 0\n",
    "\n",
    "    print(train_indices, val_indices)\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.autocast( device_type = 'cuda'):\n",
    "            # outputs = model(input_ids=input_ids, attention_mask=attention_mask, extra_feature = count)\n",
    "            # loss = loss_fn(outputs, labels.squeeze() )\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels = labels)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds, )\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"---------- Epoch {epoch} ------------\")\n",
    "    print(f\"Training Loss : {epoch_loss}\\n\")\n",
    "    print(f\"Training Accuracy : {acc}\\n\")\n",
    "    print(f\"Training Precision : {precision}\\n\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "\n",
    "    preds, labels = evaluate_model(val_df, val_dataloader, model)\n",
    "\n",
    "    y_pred_val = pd.Series(preds, index=val_df.index)\n",
    "    y_true_val = pd.Series(labels, index= val_df.index)\n",
    "    combined_acc = pd.concat([y_pred_val, y_true_val], axis = 1)\\\n",
    "        .groupby(\"MatchID\")\\\n",
    "        .apply(lambda x: accuracy_score(x[1], x[0]))\n",
    "\n",
    "\n",
    "    print(combined_acc)\n",
    "    scheduler.step(combined_acc.min())\n",
    "\n",
    "    if combined_acc.min() > best_acc:\n",
    "        best_acc = combined_acc.min()\n",
    "        best_model = deepcopy(model)\n",
    "\n",
    "\n",
    "# Combine results for this fold\n",
    "# validation_results = pd.DataFrame({\n",
    "#     \"MatchID\": validation_data[\"MatchID\"].values,\n",
    "#     \"true_values\": labels,\n",
    "#     \"predictions\": preds,\n",
    "# })\n",
    "\n",
    "# final_results.append(validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6538461538461539"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.6307692307692307\n",
      "\n",
      "Validation auc : 0.6267440295494311\n",
      "\n",
      "[[137  96]\n",
      " [ 96 191]]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TextDataset(\n",
    "    test_df[\"Tweet\"].tolist(), \n",
    "    test_df['ID'].tolist(),\n",
    "    test_df[\"EventType\"].tolist(), \n",
    "    tokenizer,\n",
    "    test_df.index.get_level_values(\"MatchID\").tolist()\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "\n",
    "preds, labels = evaluate_model(test_df, test_dataloader, best_model, extra_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchID\n",
      "13    0.676923\n",
      "14    0.515385\n",
      "17    0.676923\n",
      "18    0.653846\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = pd.Series(preds, index=test_df.index)\n",
    "y_true_val = pd.Series(labels, index= test_df.index)\n",
    "combined_acc = pd.concat([y_pred_val, y_true_val], axis = 1)\\\n",
    "    .groupby(\"MatchID\")\\\n",
    "    .apply(lambda x: accuracy_score(x[1], x[0]))\n",
    "\n",
    "\n",
    "print(combined_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "total_test_df = get_eval_set().set_index([\"MatchID\", \"PeriodID\"])\n",
    "test_df = preprocess_data(total_test_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2022/pedro.silva/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 362397/362397 [00:26<00:00, 13903.77it/s]\n",
      "100%|██████████| 362397/362397 [00:00<00:00, 719927.55it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data')\n",
    "test_df['tokens'] = test_df['Tweet'].progress_apply(tokenizer.tokenize)\n",
    "\n",
    "target_words = [\n",
    "    \"goal\", \"penalty\", \"halftime\", \"full-time\", \"yellow\", \"red\",\n",
    "    \"kickoff\", \"extra time\", \"stoppage time\", \"foul\", \"offside\", \"handball\",\n",
    "    \"save\", \"tackle\", \"dribble\", \"corner\", \"substitution\", \"header\",\n",
    "    \"free kick\", \"throw-in\", \"assist\", \"hat-trick\", \"own goal\", \"victory\",\n",
    "    \"defeat\", \"draw\", \"win\", \"loss\", \"tie\", \"comeback\", \"goalkeeper\",\n",
    "    \"striker\", \"midfielder\", \"defender\", \"referee\", \"fans\", \"var\", \"gooal\"\n",
    "]\n",
    "target_words = set(tokenizer.tokenize(\" \".join(target_words)))\n",
    "\n",
    "def is_valid_text(t):\n",
    "    for w in t:\n",
    "        if w in target_words:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "test_df['is_valid']= test_df['tokens'].progress_apply(is_valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['language'] = test_df['lan'].apply(lambda x: x[0])\n",
    "test_df['language'] = \"en\"\n",
    "\n",
    "# test_df_en = test_df.query(\"language == 'en' \")\n",
    "test_df_en = test_df.query(\"is_valid == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_df = test_df_en.groupby([\"MatchID\", \"PeriodID\"]).agg({\n",
    "    \"Tweet\":   lambda x: get_first_texts(x, max_size=15),\n",
    "    \"ID\": len\n",
    "})\n",
    "\n",
    "processed_test_df = remove_hashtag_links(processed_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th>0</th>\n",
       "      <td>Fascinated for this  match. This will tell us ...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"In a few minutes  of  x ...Can't wait\"....Waa...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want Germany to win. \\n Germany Vs. Ghana ki...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's go ! Hoping for Schweinsteiger to at lea...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Come on black   for the win! Down those  wanke...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">16</th>\n",
       "      <th>125</th>\n",
       "      <td>T-minus 5 minutes until my morning productivit...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Stat comparison between Serbia &amp; Germany s int...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Zum GlÃ¼ck hat wenigstens KEINER beim Tippspie...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>ç›´å‰äºˆæƒ³0-0ã¯å¤–ã‚Œã€‚ã‚»ãƒ«ãƒ“ã‚¢å„ªä½ã...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Five hours till kick-off!!!!  \\nCara os cara  ...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Tweet   ID\n",
       "MatchID PeriodID                                                        \n",
       "6       0         Fascinated for this  match. This will tell us ...   82\n",
       "        1         \"In a few minutes  of  x ...Can't wait\"....Waa...   85\n",
       "        2         I want Germany to win. \\n Germany Vs. Ghana ki...   79\n",
       "        3         Let's go ! Hoping for Schweinsteiger to at lea...  110\n",
       "        4         Come on black   for the win! Down those  wanke...  151\n",
       "...                                                             ...  ...\n",
       "16      125       T-minus 5 minutes until my morning productivit...  137\n",
       "        126       Stat comparison between Serbia & Germany s int...  115\n",
       "        127       Zum GlÃ¼ck hat wenigstens KEINER beim Tippspie...  116\n",
       "        128       ç›´å‰äºˆæƒ³0-0ã¯å¤–ã‚Œã€‚ã‚»ãƒ«ãƒ“ã‚¢å„ªä½ã...  109\n",
       "        129       Five hours till kick-off!!!!  \\nCara os cara  ...   94\n",
       "\n",
       "[516 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TextDataset(\n",
    "    processed_test_df[\"Tweet\"].tolist(), \n",
    "    processed_test_df['ID'].tolist(), \n",
    "    None,\n",
    "    tokenizer,\n",
    "    [0] * 516\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:12<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "preds, labels, probas = evaluate_model(processed_test_df, test_dataloader, best_model, use_labels=False, return_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_df['EventType'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "0    0.643411\n",
       "1    0.356589\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_df['EventType'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    total_test_df,\n",
    "    processed_test_df[[\"Tweet\", \"EventType\"]],\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "\n",
    ")[['EventType','ID']]\\\n",
    "    .drop_duplicates(\"ID\")\\\n",
    "    .set_index(\"ID\")\\\n",
    "    .to_csv(\"predictions_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "0    0.831609\n",
       "1    0.168391\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
