{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-Of-Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "while 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from src.utils import train_test_split, aggregate_samples, remove_hashtag_links\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from src.preprocessing import TextDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, roc_auc_score\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, LoggingHandler\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from sklearn.decomposition import PCA\n",
    "from huggingface_hub import notebook_login\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import defaultdict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from src.cross_val import KFoldSplitter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from src.feature_extraction import lemmatize_text\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "\n",
    "# Configure the logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',  # Log message format\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logs/bow.log\"),  # Log messages to a file\n",
    "        logging.StreamHandler()         # Log messages to the console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:12<00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data, _ = train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1472980/1472980 [04:05<00:00, 5990.03it/s]\n",
      "100%|██████████| 1472980/1472980 [00:02<00:00, 497669.86it/s]\n"
     ]
    }
   ],
   "source": [
    "all_df = pd.concat(train_data)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", )\n",
    "all_df['tokens'] = all_df['Tweet'].progress_apply(tokenizer.tokenize)\n",
    "\n",
    "target_words = [\n",
    "    \"goal\", \"penalty\", \"halftime\", \"full-time\", \"yellow\", \"red\",\n",
    "    \"kickoff\", \"extra time\", \"stoppage time\", \"foul\", \"offside\", \"handball\",\n",
    "    \"save\", \"tackle\", \"dribble\", \"corner\", \"substitution\", \"header\",\n",
    "    \"free kick\", \"throw-in\", \"assist\", \"hat-trick\", \"own goal\", \"victory\",\n",
    "    \"defeat\", \"draw\", \"win\", \"loss\", \"tie\", \"comeback\", \"goalkeeper\",\n",
    "    \"striker\", \"midfielder\", \"defender\", \"referee\", \"fans\", \"var\", \"gooal\"\n",
    "]\n",
    "target_words = set(tokenizer.tokenize(\" \".join(target_words)))\n",
    "\n",
    "def is_valid_text(t):\n",
    "    for w in t:\n",
    "        if w in target_words:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "all_df['is_valid']= all_df['tokens'].progress_apply(is_valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = all_df.query(\"is_valid == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokens</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>14</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725802000</td>\n",
       "      <td>Let's go Honduras, with a little help from Fra...</td>\n",
       "      <td>[let, ', s, go, honduras, ,, with, a, little, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725806000</td>\n",
       "      <td>The more goals France scores today the less go...</td>\n",
       "      <td>[the, more, goals, france, scores, today, the,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725806000</td>\n",
       "      <td>#ECU must match or better #SUI performance aga...</td>\n",
       "      <td>[#, ec, ##u, must, match, or, better, #, sui, ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725807000</td>\n",
       "      <td>Robbie Fowler predicting a Honduras win? #Worl...</td>\n",
       "      <td>[robbie, fowler, predicting, a, honduras, win,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1403725818000</td>\n",
       "      <td>I’m following Honduras versus Switzerland in t...</td>\n",
       "      <td>[i, ’, m, following, honduras, versus, switzer...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">19</th>\n",
       "      <th>155330</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560798000</td>\n",
       "      <td>Great win can't wait for next game #MEX</td>\n",
       "      <td>[great, win, can, ', t, wait, for, next, game,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155360</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560798000</td>\n",
       "      <td>If they wouldn't have robbed Mexico in the fir...</td>\n",
       "      <td>[if, they, wouldn, ', t, have, robbed, mexico,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155448</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560799000</td>\n",
       "      <td>Round of 16 - 29 de Junio #MEX vs #NED #Brasil...</td>\n",
       "      <td>[round, of, 16, -, 29, de, jun, ##io, #, me, #...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155458</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560799000</td>\n",
       "      <td>Holland better not let up, El Tri is coming fo...</td>\n",
       "      <td>[holland, better, not, let, up, ,, el, tri, is...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155480</th>\n",
       "      <td>19_129</td>\n",
       "      <td>19</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1403560800000</td>\n",
       "      <td>Brazil vs Mexico in the knockout rounds? I'm r...</td>\n",
       "      <td>[brazil, vs, mexico, in, the, knockout, rounds...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593434 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  MatchID  PeriodID  EventType      Timestamp  \\\n",
       "0  14         0_0        0         0          0  1403725802000   \n",
       "   29         0_0        0         0          0  1403725806000   \n",
       "   34         0_0        0         0          0  1403725806000   \n",
       "   36         0_0        0         0          0  1403725807000   \n",
       "   76         0_0        0         0          0  1403725818000   \n",
       "...           ...      ...       ...        ...            ...   \n",
       "19 155330  19_129       19       129          1  1403560798000   \n",
       "   155360  19_129       19       129          1  1403560798000   \n",
       "   155448  19_129       19       129          1  1403560799000   \n",
       "   155458  19_129       19       129          1  1403560799000   \n",
       "   155480  19_129       19       129          1  1403560800000   \n",
       "\n",
       "                                                       Tweet  \\\n",
       "0  14      Let's go Honduras, with a little help from Fra...   \n",
       "   29      The more goals France scores today the less go...   \n",
       "   34      #ECU must match or better #SUI performance aga...   \n",
       "   36      Robbie Fowler predicting a Honduras win? #Worl...   \n",
       "   76      I’m following Honduras versus Switzerland in t...   \n",
       "...                                                      ...   \n",
       "19 155330            Great win can't wait for next game #MEX   \n",
       "   155360  If they wouldn't have robbed Mexico in the fir...   \n",
       "   155448  Round of 16 - 29 de Junio #MEX vs #NED #Brasil...   \n",
       "   155458  Holland better not let up, El Tri is coming fo...   \n",
       "   155480  Brazil vs Mexico in the knockout rounds? I'm r...   \n",
       "\n",
       "                                                      tokens  is_valid  \n",
       "0  14      [let, ', s, go, honduras, ,, with, a, little, ...      True  \n",
       "   29      [the, more, goals, france, scores, today, the,...      True  \n",
       "   34      [#, ec, ##u, must, match, or, better, #, sui, ...      True  \n",
       "   36      [robbie, fowler, predicting, a, honduras, win,...      True  \n",
       "   76      [i, ’, m, following, honduras, versus, switzer...      True  \n",
       "...                                                      ...       ...  \n",
       "19 155330  [great, win, can, ', t, wait, for, next, game,...      True  \n",
       "   155360  [if, they, wouldn, ', t, have, robbed, mexico,...      True  \n",
       "   155448  [round, of, 16, -, 29, de, jun, ##io, #, me, #...      True  \n",
       "   155458  [holland, better, not, let, up, ,, el, tri, is...      True  \n",
       "   155480  [brazil, vs, mexico, in, the, knockout, rounds...      True  \n",
       "\n",
       "[593434 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [LogisticRegression(), RandomForestClassifier(), RandomForestClassifier(max_depth=5), DecisionTreeClassifier(), MLPClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = classifiers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/pedro/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/pedro/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/pedro/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/pedro/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "100%|██████████| 593434/593434 [02:35<00:00, 3804.42it/s]\n",
      "/tmp/ipykernel_958003/1007625579.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valid_df['tokens'] = valid_df['Tweet'].progress_apply(lemmatize_text)\n"
     ]
    }
   ],
   "source": [
    "valid_df['tokens'] = valid_df['Tweet'].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-03 16:12:29,405 - __main__ - INFO - Fold 9 - Validation indices = [0, 2, 7, 12]\n",
      "2024-12-03 16:12:29,408 - __main__ - INFO - Accuracy = 0.5174537987679672\n",
      "10it [00:57,  5.79s/it]\n",
      "2024-12-03 16:12:29,415 - __main__ - INFO - Mean Accuracy for MLPClassifier():  0.520840704470068\n"
     ]
    }
   ],
   "source": [
    "splitter = KFoldSplitter([0,1,2,5,12,19,7,11,13,18], val_size=4)\n",
    "splits = splitter.split()\n",
    "folds = np.random.choice(splits, size=10)\n",
    "\n",
    "classifiers = [LogisticRegression(), RandomForestClassifier(), RandomForestClassifier(max_depth=5), DecisionTreeClassifier(), MLPClassifier()]\n",
    "\n",
    "performances = {}\n",
    "\n",
    "for clf in classifiers:\n",
    "    logger.info(f\"\\n\\nUsing Classifier {clf}\")\n",
    "\n",
    "    accuracies_list = []\n",
    "    for i, split_idx in tqdm(enumerate(folds)):\n",
    "        \n",
    "        train_indices, val_indices = split_idx['train_indices'], split_idx['val_indices']\n",
    "\n",
    "        train_df = aggregate_samples(valid_df, train_indices, max_tweet_size = 10, tweet_col='tokens')\n",
    "        train_df = remove_hashtag_links(train_df, tweet_col=\"tokens\")\n",
    "\n",
    "        val_df = aggregate_samples(valid_df, val_indices, max_tweet_size = 10, tweet_col='tokens')\n",
    "        val_df = remove_hashtag_links(val_df, tweet_col=\"tokens\")\n",
    "\n",
    "        forced_words = [\n",
    "            \"goal\", \"penalty\", \"halftime\", \"full\", \"time\", \"yellow\", \"red\",\n",
    "            \"kickoff\", \"extra\", \"stoppage\", \"foul\", \"offside\", \"handball\",\n",
    "            \"save\", \"tackle\", \"dribble\", \"corner\", \"substitution\", \"header\",\n",
    "            \"free\", \"kick\", \"throw\", \"assist\", \"hat\", \"trick\", \"own\", \"victory\",\n",
    "            \"defeat\", \"draw\", \"win\", \"loss\", \"tie\", \"comeback\", \"goalkeeper\",\n",
    "            \"striker\", \"midfielder\", \"defender\", \"referee\", \"fans\", \"var\", \"goooal\"\n",
    "        ]  # Words to force into the vectorizer\n",
    "\n",
    "        # forced_words = \" \".join(forced_words)\n",
    "        # forced_words = set(tokenizer.tokenize(forced_words))\n",
    "\n",
    "        custom_vocab = {word: i for i, word in enumerate(forced_words)}\n",
    "\n",
    "        vectorizer = TfidfVectorizer(max_features=200)\n",
    "        # vectorizer = TfidfVectorizer(vocabulary=custom_vocab)\n",
    "        vectorizer.fit_transform(train_df['tokens'])\n",
    "        y_train = train_df['EventType']\n",
    "\n",
    "\n",
    "        # original_vocab = set(vectorizer.get_feature_names_out())\n",
    "\n",
    "        # # Combine original vocabulary with forced words\n",
    "        # combined_vocab = sorted(original_vocab.union(forced_words))\n",
    "\n",
    "        # Reinitialize the vectorizer with the combined vocabulary\n",
    "        # vectorizer = TfidfVectorizer(vocabulary=combined_vocab)\n",
    "\n",
    "        X_train = vectorizer.fit_transform(train_df['tokens'])\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        features_val = vectorizer.transform(val_df['tokens'])\n",
    "        target_val = val_df['EventType']\n",
    "\n",
    "        y_pred_val = clf.predict_proba(features_val)\n",
    "        \n",
    "        clear_output()\n",
    "        logger.info(f\"Fold {i} - Validation indices = {val_indices}\")\n",
    "        \n",
    "        fold_accuracy = accuracy_score(target_val, y_pred_val[:,1] > 0.5)\n",
    "        logger.info(f\"Accuracy = {fold_accuracy}\")\n",
    "        \n",
    "        confusion_matrix(target_val, y_pred_val[:,1] > 0.5)\n",
    "        accuracies_list.append(fold_accuracy)\n",
    "\n",
    "    logger.info(f\"Mean Accuracy for {clf}:  {np.mean(accuracies_list)}\")\n",
    "    performances[clf.__str__()] = np.mean(accuracies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
