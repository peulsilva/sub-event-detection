{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "while 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from src.utils import train_test_split, get_sample_weights, get_eval_set\n",
    "from src.preprocessing import preprocess_data\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from src.preprocessing import TextDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, roc_auc_score\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, LoggingHandler\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from sklearn.decomposition import PCA\n",
    "from huggingface_hub import notebook_login\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from collections import defaultdict\n",
    "import transformers\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import re\n",
    "from bert_score import BERTScorer\n",
    "import langid\n",
    "from src.utils import aggregate_samples, evaluate_model, compute_class_weights, remove_hashtag_links, get_first_texts\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from transformers import BitsAndBytesConfig, DataCollatorWithPadding\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"summary.pkl\")\n",
    "data['match_id'] = data['text_idx'].apply(lambda x: x[0])\n",
    "data['period_id'] = data['text_idx'].apply(lambda x: x[1])\n",
    "\n",
    "data = data.set_index(['match_id', 'period_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible_indices = set(train_data.keys())\n",
    "\n",
    "# test_indices = list(np.random.choice(list(possible_indices), size=3, replace = False,))\n",
    "# test_indices = [13,1,18]\n",
    "# all_train_indices = list(possible_indices.difference(set(test_indices)))\n",
    "val_indices = [1,5,4,12,19]\n",
    "# val_indices = list(np.random.choice(all_train_indices, 3, replace=False))\n",
    "# train_indices = list(set(all_train_indices).difference(set(val_indices)))\n",
    "train_indices = [0,3,2,7,11,]\n",
    "\n",
    "test_indices = [14,17,13, 18]\n",
    "\n",
    "train_df = data.query(f\"match_id in {train_indices}\")\n",
    "val_df = data.query(f\"match_id in {val_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = remove_hashtag_links(train_df)\n",
    "# test_df = remove_hashtag_links(test_df)\n",
    "# val_df = remove_hashtag_links(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 17, 13, 18]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96312/82084156.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['ID'] = 0\n",
      "/tmp/ipykernel_96312/82084156.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_df['ID'] = 0\n"
     ]
    }
   ],
   "source": [
    "train_df['ID'] = 0\n",
    "val_df['ID'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.5768645357686454\n",
      "\n",
      "Validation auc : 0.586009110346751\n",
      "\n",
      "[[232  78]\n",
      " [200 147]]\n",
      "match_id\n",
      "1     0.576923\n",
      "4     0.570588\n",
      "5     0.584615\n",
      "12    0.639175\n",
      "19    0.530769\n",
      "dtype: float64\n",
      "[0, 3, 2, 7, 11] [1, 5, 4, 12, 19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/82 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 43/82 [00:03<00:03, 12.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 87\u001b[0m\n\u001b[1;32m     83\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     86\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 87\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     90\u001b[0m all_preds\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_compile.py:31\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     29\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:600\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m prior \u001b[38;5;241m=\u001b[39m set_eval_frame(callback)\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/optim/optimizer.py:947\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 947\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K Fold CV\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\", cache_dir = '/Data')\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "final_results = []\n",
    "\n",
    "\n",
    "train_dataset = TextDataset(\n",
    "    train_df[\"generated_text\"].tolist(), \n",
    "    train_df['ID'].tolist(),\n",
    "    train_df[\"label\"].tolist(), \n",
    "    tokenizer,\n",
    "    train_df.index.get_level_values(\"match_id\").tolist()\n",
    "\n",
    ")\n",
    "\n",
    "val_dataset = TextDataset(\n",
    "    val_df[\"generated_text\"].tolist(), \n",
    "    val_df['ID'].tolist(),\n",
    "    val_df[\"label\"].tolist(), \n",
    "    tokenizer,\n",
    "    val_df.index.get_level_values(\"match_id\").tolist()\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, )\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", cache_dir = '/Data', num_labels = 2,ignore_mismatched_sizes=True)\n",
    "# for p in base_model.model.parameters():\n",
    "#     p.requires_grad = False\n",
    "model.to(device)\n",
    "\n",
    "# model = get_peft_model(base_model, lora_config)\n",
    "# for param in model.bert.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "for name, param in model.bert.named_parameters():\n",
    "    if \"layer.11\" in name or \"layer.10\":  # Unfreeze last two layers\n",
    "        param.requires_grad = True\n",
    "\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "labels = train_df[\"label\"].tolist()\n",
    "\n",
    "class_weights = compute_class_weights(train_df['label']).to(device)\n",
    "# class_weights = torch.Tensor([0.6,0.4]).to(device)\n",
    "\n",
    "# Define weighted loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss(class_weights)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    epoch_loss = 0\n",
    "\n",
    "    print(train_indices, val_indices)\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        with torch.autocast( device_type = 'cuda'):\n",
    "            # outputs = model(input_ids=input_ids, attention_mask=attention_mask, extra_feature = count)\n",
    "            # loss = loss_fn(outputs, labels.squeeze() )\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels = labels)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds, )\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"---------- Epoch {epoch} ------------\")\n",
    "    print(f\"Training Loss : {epoch_loss}\\n\")\n",
    "    print(f\"Training Accuracy : {acc}\\n\")\n",
    "    print(f\"Training Precision : {precision}\\n\")\n",
    "    print(conf_matrix)\n",
    "\n",
    "\n",
    "    preds, labels = evaluate_model(val_df, val_dataloader, model)\n",
    "\n",
    "    y_pred_val = pd.Series(preds, index=val_df.index)\n",
    "    y_true_val = pd.Series(labels, index= val_df.index)\n",
    "    combined_acc = pd.concat([y_pred_val, y_true_val], axis = 1)\\\n",
    "        .groupby(\"match_id\")\\\n",
    "        .apply(lambda x: accuracy_score(x[1], x[0]))\n",
    "\n",
    "\n",
    "    print(combined_acc)\n",
    "    scheduler.step(combined_acc.min())\n",
    "\n",
    "    if combined_acc.min() > best_acc:\n",
    "        best_acc = combined_acc.min()\n",
    "        best_model = deepcopy(model)\n",
    "\n",
    "\n",
    "# Combine results for this fold\n",
    "# validation_results = pd.DataFrame({\n",
    "#     \"MatchID\": validation_data[\"MatchID\"].values,\n",
    "#     \"true_values\": labels,\n",
    "#     \"predictions\": preds,\n",
    "# })\n",
    "\n",
    "# final_results.append(validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130     0\n",
       "131     0\n",
       "132     0\n",
       "133     0\n",
       "134     1\n",
       "       ..\n",
       "2132    1\n",
       "2133    1\n",
       "2134    1\n",
       "2135    1\n",
       "2136    1\n",
       "Length: 657, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6538461538461539"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy : 0.6307692307692307\n",
      "\n",
      "Validation auc : 0.6267440295494311\n",
      "\n",
      "[[137  96]\n",
      " [ 96 191]]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TextDataset(\n",
    "    test_df[\"Tweet\"].tolist(), \n",
    "    test_df['ID'].tolist(),\n",
    "    test_df[\"EventType\"].tolist(), \n",
    "    tokenizer,\n",
    "    test_df.index.get_level_values(\"MatchID\").tolist()\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "\n",
    "preds, labels = evaluate_model(test_df, test_dataloader, best_model, extra_feature=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchID\n",
      "13    0.676923\n",
      "14    0.515385\n",
      "17    0.676923\n",
      "18    0.653846\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = pd.Series(preds, index=test_df.index)\n",
    "y_true_val = pd.Series(labels, index= test_df.index)\n",
    "combined_acc = pd.concat([y_pred_val, y_true_val], axis = 1)\\\n",
    "    .groupby(\"MatchID\")\\\n",
    "    .apply(lambda x: accuracy_score(x[1], x[0]))\n",
    "\n",
    "\n",
    "print(combined_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "total_test_df = get_eval_set().set_index([\"MatchID\", \"PeriodID\"])\n",
    "test_df = preprocess_data(total_test_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2022/pedro.silva/.local/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 362397/362397 [00:26<00:00, 13903.77it/s]\n",
      "100%|██████████| 362397/362397 [00:00<00:00, 719927.55it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\", cache_dir = '/Data')\n",
    "test_df['tokens'] = test_df['Tweet'].progress_apply(tokenizer.tokenize)\n",
    "\n",
    "target_words = [\n",
    "    \"goal\", \"penalty\", \"halftime\", \"full-time\", \"yellow\", \"red\",\n",
    "    \"kickoff\", \"extra time\", \"stoppage time\", \"foul\", \"offside\", \"handball\",\n",
    "    \"save\", \"tackle\", \"dribble\", \"corner\", \"substitution\", \"header\",\n",
    "    \"free kick\", \"throw-in\", \"assist\", \"hat-trick\", \"own goal\", \"victory\",\n",
    "    \"defeat\", \"draw\", \"win\", \"loss\", \"tie\", \"comeback\", \"goalkeeper\",\n",
    "    \"striker\", \"midfielder\", \"defender\", \"referee\", \"fans\", \"var\", \"gooal\"\n",
    "]\n",
    "target_words = set(tokenizer.tokenize(\" \".join(target_words)))\n",
    "\n",
    "def is_valid_text(t):\n",
    "    for w in t:\n",
    "        if w in target_words:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "test_df['is_valid']= test_df['tokens'].progress_apply(is_valid_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df['language'] = test_df['lan'].apply(lambda x: x[0])\n",
    "test_df['language'] = \"en\"\n",
    "\n",
    "# test_df_en = test_df.query(\"language == 'en' \")\n",
    "test_df_en = test_df.query(\"is_valid == 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_df = test_df_en.groupby([\"MatchID\", \"PeriodID\"]).agg({\n",
    "    \"Tweet\":   lambda x: get_first_texts(x, max_size=15),\n",
    "    \"ID\": len\n",
    "})\n",
    "\n",
    "processed_test_df = remove_hashtag_links(processed_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MatchID</th>\n",
       "      <th>PeriodID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th>0</th>\n",
       "      <td>Fascinated for this  match. This will tell us ...</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"In a few minutes  of  x ...Can't wait\"....Waa...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I want Germany to win. \\n Germany Vs. Ghana ki...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Let's go ! Hoping for Schweinsteiger to at lea...</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Come on black   for the win! Down those  wanke...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">16</th>\n",
       "      <th>125</th>\n",
       "      <td>T-minus 5 minutes until my morning productivit...</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Stat comparison between Serbia &amp; Germany s int...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Zum GlÃ¼ck hat wenigstens KEINER beim Tippspie...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>ç›´å‰äºˆæƒ³0-0ã¯å¤–ã‚Œã€‚ã‚»ãƒ«ãƒ“ã‚¢å„ªä½ã...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Five hours till kick-off!!!!  \\nCara os cara  ...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Tweet   ID\n",
       "MatchID PeriodID                                                        \n",
       "6       0         Fascinated for this  match. This will tell us ...   82\n",
       "        1         \"In a few minutes  of  x ...Can't wait\"....Waa...   85\n",
       "        2         I want Germany to win. \\n Germany Vs. Ghana ki...   79\n",
       "        3         Let's go ! Hoping for Schweinsteiger to at lea...  110\n",
       "        4         Come on black   for the win! Down those  wanke...  151\n",
       "...                                                             ...  ...\n",
       "16      125       T-minus 5 minutes until my morning productivit...  137\n",
       "        126       Stat comparison between Serbia & Germany s int...  115\n",
       "        127       Zum GlÃ¼ck hat wenigstens KEINER beim Tippspie...  116\n",
       "        128       ç›´å‰äºˆæƒ³0-0ã¯å¤–ã‚Œã€‚ã‚»ãƒ«ãƒ“ã‚¢å„ªä½ã...  109\n",
       "        129       Five hours till kick-off!!!!  \\nCara os cara  ...   94\n",
       "\n",
       "[516 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TextDataset(\n",
    "    processed_test_df[\"Tweet\"].tolist(), \n",
    "    processed_test_df['ID'].tolist(), \n",
    "    None,\n",
    "    tokenizer,\n",
    "    [0] * 516\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:12<00:00,  1.33it/s]\n"
     ]
    }
   ],
   "source": [
    "preds, labels, probas = evaluate_model(processed_test_df, test_dataloader, best_model, use_labels=False, return_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_df['EventType'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "0    0.643411\n",
       "1    0.356589\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test_df['EventType'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(\n",
    "    total_test_df,\n",
    "    processed_test_df[[\"Tweet\", \"EventType\"]],\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    "\n",
    ")[['EventType','ID']]\\\n",
    "    .drop_duplicates(\"ID\")\\\n",
    "    .set_index(\"ID\")\\\n",
    "    .to_csv(\"predictions_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EventType\n",
       "0    0.831609\n",
       "1    0.168391\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
